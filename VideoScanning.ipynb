{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-dSJzHUBft0"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFIyaNN-Aw1m"
      },
      "outputs": [],
      "source": [
        "!pip uninstall easyocr\n",
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWtw5ILuT2vr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "\n",
        "# Open the video file\n",
        "video_path = 'UjiVideo.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening the video:\", video_path)\n",
        "    exit()\n",
        "\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame was read successfully\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Resize the frame (you can adjust the dimensions as needed)\n",
        "    frame = cv2.resize(frame, (812, 812))\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to the frame\n",
        "    img_blurred = cv2.GaussianBlur(frame, (5, 5), 1)\n",
        "\n",
        "    # Apply Canny edge detection to the blurred frame\n",
        "    edge_image_blurred = cv2.Canny(img_blurred, 60, 180)\n",
        "\n",
        "    # Create a kernel for dilation\n",
        "    kernel = np.ones((5, 5))\n",
        "\n",
        "    # Dilate the edge-detected image\n",
        "    imgDil = cv2.dilate(edge_image_blurred, kernel, iterations=2)\n",
        "\n",
        "    # Find contours in the dilated image\n",
        "    contours, _ = cv2.findContours(imgDil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Draw all contours on the original frame\n",
        "    cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the processed frame\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Use easyocr to extract text\n",
        "    reader = easyocr.Reader(['en'], gpu=False)\n",
        "    text_ = reader.readtext(frame)\n",
        "\n",
        "    threshold = 0.25\n",
        "    for t in text_:\n",
        "      print(t)\n",
        "      bbox, text, score = t\n",
        "\n",
        "      if score > threshold:\n",
        "        cv2.rectangle(frame, bbox[0], bbox[2], (0,255,0),5)\n",
        "        cv2.putText(frame, text, bbox[0], cv2.FONT_HERSHEY_COMPLEX,0.65,(255,0,0),2)\n",
        "    plt.imshow(frame)\n",
        "    plt.show()\n",
        "\n",
        "    # Check for user input to exit the loop\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}